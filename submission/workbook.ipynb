{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A41frfMPerG"
      },
      "source": [
        "# RvF - Starter Code Workbook\n",
        "\n",
        "This is a workbook that you can upload to Google Colab to work on the project. It will download all the correct files and details to work on model development and improving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1GmkkgQPvUJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change this to the folder containing your Kaggle API key (kaggle.json)\n",
        "%env KAGGLE_KEY_FOLDER=MDST/RvF\n",
        "!mkdir data\n",
        "!export KAGGLE_CONFIG_DIR=/content/drive/MyDrive/$KAGGLE_KEY_FOLDER && wget -O - \"https://raw.githubusercontent.com/MichiganDataScienceTeam/W24-RvF/main/data/download.sh\" | bash -s rvf10k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6FeX-fyP2ZV"
      },
      "outputs": [],
      "source": [
        "!rm -r W24-RvF starter_code\n",
        "!git clone -q https://github.com/MichiganDataScienceTeam/W24-RvF.git\n",
        "!mv W24-RvF/starter_code .\n",
        "!rm -r W24-RvF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARe20g8XRvvM"
      },
      "source": [
        "**KEY**: Make sure to save your work after every meeting! We recommend you do so via GitHub, but its not necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpQSgNMIhA7r"
      },
      "source": [
        "The following sample code is the basics you need to get started with model development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BvrSyAvbiFOL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def preprocess(image) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Preprocesses an image by applying a series of transformation.\n",
        "\n",
        "    Args:\n",
        "        image (npt.ArrayLike): The input image to be preprocessed.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The preprocessed image as a tensor.\n",
        "    \"\"\"\n",
        "    # TODO: Edit this function to more preprocessing steps to improve model performance.\n",
        "    tensor = torch.tensor(image, dtype=torch.float32)\n",
        "    return tensor.permute(2,0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "H8KJJOQQhA7r"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    # TODO: Define your model here!\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5wM5_FgR5GG"
      },
      "outputs": [],
      "source": [
        "from starter_code.dataset import get_loaders\n",
        "from starter_code.train import train_model, plot_performance, load_model\n",
        "\n",
        "train_loader, val_loader = get_loaders(preprocessor=preprocess)\n",
        "\n",
        "model = Model()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) # TODO: Change the optimizer to explore different options\n",
        "criterion = torch.nn.CrossEntropyLoss() # TODO: Change the criterion to explore different options\n",
        "\n",
        "history = train_model(model, criterion, optimizer, train_loader, val_loader, epochs=5)\n",
        "plot_performance(history)\n",
        "\n",
        "# Load the model from the training run\n",
        "load_model(model, \"checkpoints\", 0) # change epoch from 0 to something else"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwibsJyzhA7s"
      },
      "source": [
        "**KEY**: At the end of each work session, submit this workbook via slack! This will allow the project leads to train your model on the larger 140k dataset over the week!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
